{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOOecrQ2Wpn1wL+g6J0Xzxc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollyjuice74/Error-Bit-Decoding/blob/main/BCHDecoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# general imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load required Sionna components\n",
        "!pip install sionna\n",
        "import sionna as sn\n",
        "from sionna.fec.utils import load_parity_check_examples, LinearEncoder, GaussianPriorSource\n",
        "from sionna.utils import BinarySource, ebnodb2no, BitwiseMutualInformation, hard_decisions\n",
        "from sionna.utils.metrics import compute_ber\n",
        "from sionna.utils.plotting import PlotBER\n",
        "from sionna.mapping import Mapper, Demapper\n",
        "from sionna.channel import AWGN\n",
        "from sionna.fec.ldpc import LDPCBPDecoder\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Layer\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import sys\n",
        "from importlib import import_module\n",
        "import pickle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "#tf.config.experimental_run_functions_eagerly(True)\n",
        "from drive.MyDrive.gnn_decoder.gnn import *\n",
        "from drive.MyDrive.gnn_decoder.wbp import * # load weighted BP functions"
      ],
      "metadata": {
        "id": "Vyfrd-EAsv37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#----- BCH -----\n",
        "params={\n",
        "    # --- Code Parameters ---\n",
        "        \"code\": \"BCH\", # (63,45)\n",
        "    # --- GNN Architecture ----\n",
        "        \"num_embed_dims\": 20,\n",
        "        \"num_msg_dims\": 20,\n",
        "        \"num_hidden_units\": 40,\n",
        "        \"num_mlp_layers\": 2,\n",
        "        \"num_iter\": 8,\n",
        "        \"reduce_op\": \"mean\",\n",
        "        \"activation\": \"tanh\",\n",
        "        \"clip_llr_to\": None,\n",
        "        \"use_attributes\": False,\n",
        "        \"node_attribute_dims\": 0,\n",
        "        \"msg_attribute_dims\": 0,\n",
        "        \"use_bias\": False,\n",
        "    # --- Training ---- #\n",
        "        \"batch_size\": [256, 256, 256], # bs, iter, lr must have same dim\n",
        "        \"train_iter\": [35000, 300000, 300000],\n",
        "        \"learning_rate\": [1e-3, 1e-4, 1e-5],\n",
        "        \"ebno_db_train\": [3, 8.],\n",
        "        \"ebno_db_eval\": 4.,\n",
        "        \"batch_size_eval\": 10000, # batch size only used for evaluation during training\n",
        "        \"eval_train_steps\": 1000, # evaluate model every N iters\n",
        "    # --- Log ----\n",
        "        \"save_weights_iter\": 10000, # save weights every X iters\n",
        "        \"run_name\": \"BCH_01\", # name of the stored weights/logs\n",
        "        \"save_dir\": \"results/\", # folder to store results\n",
        "    # --- MC Simulation parameters ----\n",
        "        \"mc_iters\": 1000,\n",
        "        \"mc_batch_size\": 2000,\n",
        "        \"num_target_block_errors\": 500,\n",
        "        \"ebno_db_min\": 2.,\n",
        "        \"ebno_db_max\": 9.,\n",
        "        \"ebno_db_stepsize\": 1.,\n",
        "        \"eval_iters\": [2, 3, 4, 6, 8, 10],\n",
        "    # --- Weighted BP parameters ----\n",
        "        \"simulate_wbp\": True, # simulate weighted BP as baseline\n",
        "        \"wbp_batch_size\" : [2000, 2000, 2000],\n",
        "        \"wbp_train_iter\" : [300, 10000, 2000],\n",
        "        \"wbp_learning_rate\" : [1e-2, 1e-3, 1e-3],\n",
        "        \"wbp_ebno_train\" : [5., 5., 6.],\n",
        "        \"wbp_ebno_val\" : 7., # validation SNR during training\n",
        "        \"wbp_batch_size_val\" : 2000,\n",
        "        \"wbp_clip_value_grad\" : 10,\n",
        "}"
      ],
      "metadata": {
        "id": "8zRiuXBCs0my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFbDO_tnslua",
        "outputId": "26a410cd-c3ef-46ab-cd4b-50164e612f6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BCH code\n",
            "\n",
            "n: 63, k: 45, coderate: 0.714\n",
            "Warning: The alias fec.utils.LinearEncoder will not be included in Sionna 1.0. Please use fec.linear.LinearEncoder instead.\n",
            "EbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n",
            "      2.0 | 5.9794e-02 | 8.1200e-01 |        7534 |      126000 |         1624 |        2000 |         6.8 |reached target block errors\n",
            "      3.0 | 3.1714e-02 | 4.8550e-01 |        3996 |      126000 |          971 |        2000 |         0.3 |reached target block errors\n",
            "      4.0 | 1.3381e-02 | 2.1050e-01 |        3372 |      252000 |          842 |        4000 |         0.5 |reached target block errors\n",
            "      5.0 | 3.9508e-03 | 5.8500e-02 |        2489 |      630000 |          585 |       10000 |         1.3 |reached target block errors\n",
            "      6.0 | 9.2479e-04 | 1.2071e-02 |        2447 |     2646000 |          507 |       42000 |         5.3 |reached target block errors\n",
            "\n",
            "Simulation stopped by the user @ EbNo = 7.0 dB.\n"
          ]
        }
      ],
      "source": [
        "# all codes must provide an encoder-layer and a pcm\n",
        "if params[\"code\"]==\"BCH\":\n",
        "    print(\"Loading BCH code\")\n",
        "    pcm, k, n, coderate = load_parity_check_examples(pcm_id=1, verbose=True)\n",
        "\n",
        "    encoder = LinearEncoder(pcm, is_pcm=True)\n",
        "    params[\"k\"] = k\n",
        "    params[\"n\"] = n\n",
        "else:\n",
        "    raise ValueError(\"Unknown code type\")\n",
        "\n",
        "ber_plot = PlotBER(f\"GNN-based Decoding - {params['code']}, (k,n)=({k},{n})\")\n",
        "ebno_dbs = np.arange(params[\"ebno_db_min\"],\n",
        "                     params[\"ebno_db_max\"]+1,\n",
        "                     params[\"ebno_db_stepsize\"])\n",
        "\n",
        "# simulate \"conventional\" BP performance for given pcm\n",
        "bp_decoder = LDPCBPDecoder(pcm, num_iter=20, hard_out=False)\n",
        "e2e_bp = E2EModel(encoder, bp_decoder, k, n)\n",
        "# ber_plot.simulate(e2e_bp,\n",
        "#                  ebno_dbs=ebno_dbs,\n",
        "#                  batch_size=params[\"mc_batch_size\"],\n",
        "#                  num_target_block_errors=params[\"num_target_block_errors\"],\n",
        "#                  legend=f\"BP {bp_decoder._num_iter.numpy()} iter.\",\n",
        "#                  soft_estimates=True,\n",
        "#                  max_mc_iter=params[\"mc_iters\"],\n",
        "#                  forward_keyboard_interrupt=False,\n",
        "#                  show_fig=False);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encoder.load_weights('gnn_decoder/weights/BCH_precomputed.npy')\n",
        "\n",
        "# train and simulate Weighted BP as additional baseline\n",
        "# please note that the training parameters could be critical\n",
        "if params[\"simulate_wbp\"]:\n",
        "    evaluate_wbp(params, pcm, encoder, ebno_dbs, ber_plot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DeJMuc90vpkF",
        "outputId": "b8268a66-4ed0-4026-8aeb-bcb2e12dde65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note that WBP requires Sionna > v0.11.\n",
            "Iter: 0 loss: 0.002754 ber: 0.000095 bmi: 0.999\n",
            "Iter: 50 loss: 0.001551 ber: 0.000119 bmi: 0.999\n",
            "Iter: 100 loss: 0.002035 ber: 0.000087 bmi: 0.999\n",
            "Iter: 150 loss: 0.002294 ber: 0.000103 bmi: 0.999\n",
            "Iter: 200 loss: 0.001316 ber: 0.000024 bmi: 1.000\n",
            "Iter: 250 loss: 0.001561 ber: 0.000103 bmi: 0.999\n",
            "Iter: 0 loss: 0.000573 ber: 0.000040 bmi: 1.000\n",
            "Iter: 50 loss: 0.000833 ber: 0.000032 bmi: 1.000\n",
            "Iter: 100 loss: 0.001029 ber: 0.000071 bmi: 0.999\n",
            "Iter: 150 loss: 0.001136 ber: 0.000119 bmi: 0.999\n",
            "Iter: 200 loss: 0.000692 ber: 0.000048 bmi: 1.000\n",
            "Iter: 250 loss: 0.000701 ber: 0.000040 bmi: 1.000\n",
            "Iter: 300 loss: 0.000414 ber: 0.000000 bmi: 1.000\n",
            "Iter: 350 loss: 0.000756 ber: 0.000071 bmi: 0.999\n",
            "Iter: 400 loss: 0.000902 ber: 0.000071 bmi: 1.000\n",
            "Iter: 450 loss: 0.000682 ber: 0.000087 bmi: 0.999\n",
            "Iter: 500 loss: 0.001183 ber: 0.000040 bmi: 1.000\n",
            "Iter: 550 loss: 0.001236 ber: 0.000095 bmi: 0.999\n",
            "Iter: 600 loss: 0.000524 ber: 0.000024 bmi: 1.000\n",
            "Iter: 650 loss: 0.000956 ber: 0.000079 bmi: 0.999\n",
            "Iter: 700 loss: 0.001523 ber: 0.000032 bmi: 0.995\n",
            "Iter: 750 loss: 0.000859 ber: 0.000071 bmi: 0.999\n",
            "Iter: 800 loss: 0.000621 ber: 0.000040 bmi: 1.000\n",
            "Iter: 850 loss: 0.000667 ber: 0.000048 bmi: 1.000\n",
            "Iter: 900 loss: 0.000350 ber: 0.000048 bmi: 1.000\n",
            "Iter: 950 loss: 0.000807 ber: 0.000087 bmi: 0.999\n",
            "Iter: 1000 loss: 0.000764 ber: 0.000087 bmi: 0.999\n",
            "Iter: 1050 loss: 0.000512 ber: 0.000048 bmi: 1.000\n",
            "Iter: 1100 loss: 0.000884 ber: 0.000087 bmi: 0.999\n",
            "Iter: 1150 loss: 0.000678 ber: 0.000151 bmi: 0.999\n",
            "Iter: 1200 loss: 0.000377 ber: 0.000024 bmi: 1.000\n",
            "Iter: 1250 loss: 0.001190 ber: 0.000095 bmi: 0.997\n",
            "Iter: 1300 loss: 0.000341 ber: 0.000016 bmi: 1.000\n",
            "Iter: 1350 loss: 0.001907 ber: 0.000190 bmi: 0.998\n",
            "Iter: 1400 loss: 0.000594 ber: 0.000048 bmi: 1.000\n",
            "Iter: 1450 loss: 0.001136 ber: 0.000103 bmi: 0.999\n",
            "Iter: 1500 loss: 0.000953 ber: 0.000079 bmi: 0.999\n",
            "Iter: 1550 loss: 0.000760 ber: 0.000071 bmi: 0.999\n",
            "Iter: 1600 loss: 0.001215 ber: 0.000079 bmi: 0.999\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-161ef69ef9b8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# please note that the training parameters could be critical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"simulate_wbp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mevaluate_wbp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mebno_dbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mber_plot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/gnn_decoder/wbp.py\u001b[0m in \u001b[0;36mevaluate_wbp\u001b[0;34m(params, pcm, encoder, ebno_dbs, ber_plot)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# and run the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0mmodel_wbp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_wbp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# generate new decoder object (with 20 iterations) for evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gnn_decoder/wbp.py\u001b[0m in \u001b[0;36mtrain_wbp\u001b[0;34m(self, train_param)\u001b[0m\n\u001b[1;32m    139\u001b[0m                                         train_param[\"wbp_ebno_train\"][idx])\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 grads = tf.clip_by_value(grads,\n\u001b[1;32m    143\u001b[0m                                          \u001b[0;34m-\u001b[0m\u001b[0mtrain_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"wbp_clip_value_grad\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1064\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_SelectGradV2\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1655\u001b[0m   \u001b[0mgy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m   \u001b[0mgx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ReduceGradientArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m   \u001b[0mgy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ReduceGradientArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1658\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_ReduceGradientArgs\u001b[0;34m(x, y, gx, gy)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;34m\"\"\"Reduces gradients of both arguments of a broadcasting binary op.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSmartBroadcastGradientArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mgx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ReduceGradientArg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mgy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ReduceGradientArg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36mSmartBroadcastGradientArgs\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0mx_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m   \u001b[0my_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m   if (not context.executing_eagerly() and\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0mout_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    727\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0mout_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   9581\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9582\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9583\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   9584\u001b[0m         _ctx, \"Shape\", name, input, \"out_type\", out_type)\n\u001b[1;32m   9585\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}