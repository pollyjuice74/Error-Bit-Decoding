{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollyjuice74/Error-Bit-Decoding/blob/main/DDECCT_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_k_fbfIf91j",
        "outputId": "76d930aa-0d6b-4d14-cbfb-6a3454508168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DDECC'...\n",
            "remote: Enumerating objects: 100, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 100 (delta 14), reused 35 (delta 13), pack-reused 62\u001b[K\n",
            "Receiving objects: 100% (100/100), 141.49 MiB | 23.89 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils import data\n",
        "from datetime import datetime\n",
        "import time\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "if not os.path.exists('DDECC'):\n",
        "  !git clone https://github.com/pollyjuice74/DDECC.git\n",
        "os.chdir('DDECC')\n",
        "\n",
        "from Codes import *\n",
        "from DDECC import DDECCT\n",
        "from utils import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The modifications are made so that the model trains on BCH codes of length n=63, k=45, where it says:\n",
        "\n",
        "\"### IMPORTANT ###\""
      ],
      "metadata": {
        "id": "pGW0jSfZQ5vg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI-xffVWgJWo",
        "outputId": "50635401-2ca9-4179-fe2a-60d71424b1a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to model/logs: DDECCT_Results/BCH__Code_n_63_k_45\n",
            "Args: Namespace(code_type='BCH', code_k=45, code_n=63, epochs=2000, workers=4, lr=0.0005, gpus='0', batch_size=128, test_batch_size=2048, seed=42, N_dec=2, d_model=32, h=8, sigma=0.01, code=<__main__.Code object at 0x7ec0fd2383a0>, N_steps=23, path='DDECCT_Results/BCH__Code_n_63_k_45')\n"
          ]
        }
      ],
      "source": [
        "# Setup the argument parser\n",
        "parser = argparse.ArgumentParser(description='PyTorch DDPM_ECCT')\n",
        "\n",
        "### IMPORTANT ###\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "\n",
        "# select code type, k and n                           ###\n",
        "parser.add_argument('--code_type', type=str, default='BCH', choices=['BCH', 'POLAR', 'LDPC', 'CCSDS', 'MACKAY'])\n",
        "parser.add_argument('--code_k', type=int, default=45) # k\n",
        "parser.add_argument('--code_n', type=int, default=63) # n\n",
        "\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "\n",
        "parser.add_argument('--epochs', type=int, default=2000) ## EPOCHS\n",
        "parser.add_argument('--workers', type=int, default=4)\n",
        "parser.add_argument('--lr', type=float, default=5e-4)\n",
        "parser.add_argument('--gpus', type=str, default='0', help='gpus ids')\n",
        "parser.add_argument('--batch_size', type=int, default=128)\n",
        "parser.add_argument('--test_batch_size', type=int, default=2048)\n",
        "parser.add_argument('--seed', type=int, default=42)\n",
        "parser.add_argument('--N_dec', type=int, default=2)\n",
        "parser.add_argument('--d_model', type=int, default=32)\n",
        "parser.add_argument('--h', type=int, default=8)\n",
        "parser.add_argument('--sigma', type=float, default=0.01)\n",
        "\n",
        "# Function to set seed for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "# Adjust argument parsing for notebook environments\n",
        "if 'ipykernel' in sys.argv[0] or 'colab' in sys.argv[0]:\n",
        "    args = parser.parse_args(args=[])\n",
        "else:\n",
        "    args = parser.parse_args()\n",
        "\n",
        "# Environment settings for CUDA\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpus\n",
        "\n",
        "# Apply the seed\n",
        "set_seed(args.seed)\n",
        "\n",
        "# Code setup\n",
        "class Code():\n",
        "    pass\n",
        "\n",
        "code = Code()\n",
        "code.k = args.code_k\n",
        "code.n = args.code_n\n",
        "code.code_type = args.code_type\n",
        "G, H = Get_Generator_and_Parity(code)\n",
        "code.generator_matrix = torch.from_numpy(G).transpose(0, 1).long()\n",
        "code.pc_matrix = torch.from_numpy(H).long()\n",
        "args.code = code\n",
        "args.N_steps = code.pc_matrix.shape[0] + 5  # Calculate steps\n",
        "\n",
        "# Setup model directory and\n",
        "model_dir = os.path.join('DDECCT_Results', f'{args.code_type}__Code_n_{args.code_n}_k_{args.code_k}') #__{datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")}')\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "args.path = model_dir\n",
        "\n",
        "print(f\"Path to model/logs: {model_dir}\")\n",
        "print(f\"Args: {args}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The modifications made are seen in the **FEC_Dataset** where it says:\n",
        "\n",
        "\"### IMPORTANT ###\""
      ],
      "metadata": {
        "id": "cc9SRvk2QS3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXuKlYv-n6Vj"
      },
      "outputs": [],
      "source": [
        "############ ZERO CODEWORD SET TO TRUE ###############\n",
        "class FEC_Dataset(data.Dataset):                 ####\n",
        "    def __init__(self, code, sigma, len, zero_cw=True):\n",
        "        self.code = code\n",
        "        self.sigma = sigma\n",
        "        self.len = len\n",
        "        self.generator_matrix = code.generator_matrix.transpose(0, 1)\n",
        "        self.pc_matrix = code.pc_matrix.transpose(0, 1)\n",
        "\n",
        "        self.zero_word = torch.zeros((self.code.k)).long() if zero_cw else None\n",
        "        self.zero_cw = torch.zeros((self.code.n)).long() if zero_cw else None\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.zero_cw is None:\n",
        "            m = torch.randint(0, 2, (1, self.code.k)).squeeze()\n",
        "            x = torch.matmul(m, self.generator_matrix) % 2\n",
        "        else: # SET TO TRUE\n",
        "            m = self.zero_word\n",
        "            x = self.zero_cw\n",
        "\n",
        "        std_noise = random.choice(self.sigma)\n",
        "        z = torch.randn(self.code.n) * std_noise\n",
        "        #h = torch.from_numpy(np.random.rayleigh(1,self.code.n)).float()\n",
        "        # h=1\n",
        "        # y = h*bin_to_sign(x) + z\n",
        "\n",
        "        ### IMPORTANT ###\n",
        "        #######################################################################\n",
        "        #######################################################################\n",
        "        y = x.clone()\n",
        "\n",
        "        # index to be flipped\n",
        "        ix = torch.tensor(random.sample(range(self.code.n), 3))\n",
        "        y[ix] = 1 - y[ix] # flip bits\n",
        "        y = bin_to_sign(y)\n",
        "\n",
        "        #######################################################################\n",
        "        #######################################################################\n",
        "\n",
        "        magnitude = torch.abs(y)\n",
        "        syndrome = torch.matmul(sign_to_bin(torch.sign(y)).long(),\n",
        "                                self.pc_matrix) % 2\n",
        "        syndrome = bin_to_sign(syndrome)\n",
        "        return m.float(), x.float(), z.float(), y.float(), magnitude.float(), syndrome.float()\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch, LR):\n",
        "    model.train()\n",
        "    cum_loss = cum_samples = 0\n",
        "    t = time.time()\n",
        "    for batch_idx, (m, x, z, y, magnitude, syndrome) in enumerate(\n",
        "            train_loader):\n",
        "        loss = model.loss(bin_to_sign(x))\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.ema.update(model)\n",
        "        ###\n",
        "        cum_loss += loss.item() * x.shape[0]\n",
        "        cum_samples += x.shape[0]\n",
        "        if (batch_idx+1) % 500 == 0 or batch_idx == len(train_loader) - 1:\n",
        "            print(\n",
        "                f'Training epoch {epoch}, Batch {batch_idx + 1}/{len(train_loader)}: LR={LR:.2e}, Loss={cum_loss / cum_samples:.5e}')\n",
        "    print(f'Epoch {epoch} Train Time {time.time() - t}s\\n')\n",
        "    return cum_loss / cum_samples\n",
        "\n",
        "##################################################################\n",
        "\n",
        "def test(model, device, test_loader_list, EbNo_range_test, min_FER=100, max_cum_count=1e7, min_cum_count=1e5):\n",
        "    model.eval()\n",
        "    test_loss_ber_list, test_loss_fer_list, cum_samples_all = [], [], []\n",
        "    t = time.time()\n",
        "    with torch.no_grad():\n",
        "        for ii, test_loader in enumerate(test_loader_list):\n",
        "            test_ber = test_fer = cum_count = 0.\n",
        "            _, x_pred_list, _, _ = model.p_sample_loop(next(iter(test_loader))[3])\n",
        "            test_ber_ddpm , test_fer_ddpm = [0]*len(x_pred_list), [0]*len(x_pred_list)\n",
        "            idx_conv_all = []\n",
        "            while True:\n",
        "                (m, x, z, y, magnitude, syndrome) = next(iter(test_loader))\n",
        "                x_pred, x_pred_list, idx_conv,synd_all = model.p_sample_loop(y)\n",
        "                x_pred = sign_to_bin(torch.sign(x_pred))\n",
        "\n",
        "                idx_conv_all.append(idx_conv)\n",
        "                for kk, x_pred_tmp in enumerate(x_pred_list):\n",
        "                    x_pred_tmp = sign_to_bin(torch.sign(x_pred_tmp))\n",
        "\n",
        "                    test_ber_ddpm[kk] += BER(x_pred_tmp, x) * x.shape[0]\n",
        "                    test_fer_ddpm[kk] += FER(x_pred_tmp, x) * x.shape[0]\n",
        "\n",
        "                test_ber += BER(x_pred, x) * x.shape[0]\n",
        "                test_fer += FER(x_pred, x) * x.shape[0]\n",
        "                cum_count += x.shape[0]\n",
        "                if (min_FER > 0 and test_fer > min_FER and cum_count > min_cum_count) or cum_count >= max_cum_count:\n",
        "                    if cum_count >= 1e9:\n",
        "                        print(f'Cum count reached EbN0:{EbNo_range_test[ii]}')\n",
        "                    else:\n",
        "                        print(f'FER count treshold reached EbN0:{EbNo_range_test[ii]}')\n",
        "                    break\n",
        "            idx_conv_all = torch.stack(idx_conv_all).float()\n",
        "            cum_samples_all.append(cum_count)\n",
        "            test_loss_ber_list.append(test_ber / cum_count)\n",
        "            test_loss_fer_list.append(test_fer / cum_count)\n",
        "            for kk in range(len(test_ber_ddpm)):\n",
        "                test_ber_ddpm[kk] /= cum_count\n",
        "                test_fer_ddpm[kk] /= cum_count\n",
        "            print(f'Test EbN0={EbNo_range_test[ii]}, BER={test_loss_ber_list}')\n",
        "            print(f'Test EbN0={EbNo_range_test[ii]}, BER_DDPM={test_ber_ddpm}')\n",
        "            print(f'Test EbN0={EbNo_range_test[ii]}, -ln(BER)_DDPM={[-np.log(elem) for elem in test_ber_ddpm]}')\n",
        "            print(f'Test EbN0={EbNo_range_test[ii]}, FER_DDPM={test_fer_ddpm}')\n",
        "            print(f'#It. to zero syndrome: Mean={idx_conv_all.mean()}, Std={idx_conv_all.std()}, Min={idx_conv_all.min()}, Max={idx_conv_all.max()}')\n",
        "        ###\n",
        "        print('Test FER ' + ' '.join(\n",
        "            ['{}: {:.2e}'.format(ebno, elem) for (elem, ebno)\n",
        "             in\n",
        "             (zip(test_loss_fer_list, EbNo_range_test))]))\n",
        "        print('Test BER ' + ' '.join(\n",
        "            ['{}: {:.2e}'.format(ebno, elem) for (elem, ebno)\n",
        "             in\n",
        "             (zip(test_loss_ber_list, EbNo_range_test))]))\n",
        "        print('Test -ln(BER) ' + ' '.join(\n",
        "            ['{}: {:.2e}'.format(ebno, -np.log(elem)) for (elem, ebno)\n",
        "             in\n",
        "             (zip(test_loss_ber_list, EbNo_range_test))]))\n",
        "    print(f'# of testing samples: {cum_samples_all}\\n Test Time {time.time() - t} s\\n')\n",
        "    return test_loss_ber_list, test_loss_fer_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4VhjwNEljG3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "9db0890c-8ac1-43d0-aea4-d2d7eb71d146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Best Model\n",
            "DDECCT_Results/BCH__Code_n_63_k_45\n",
            "/content/DDECC\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3b4e9682b2c4>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'best_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1024\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                 return _load(opened_zipfile,\n\u001b[0m\u001b[1;32m   1027\u001b[0m                              \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                              \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m         typed_storage = torch.storage.TypedStorage(\n\u001b[0;32m-> 1382\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m             _internal=True)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    251\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ],
      "source": [
        "code = args.code\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# MODEL #\n",
        "#################################\n",
        "model = DDECCT(args, device=device,dropout=0).to(device)\n",
        "model.ema.register(model)\n",
        "\n",
        "print('Loading Best Model')\n",
        "print(args.path)\n",
        "print(os.getcwd())\n",
        "model = torch.load(os.path.join(args.path, 'best_model')).to(device)\n",
        "#################################\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=5e-6)\n",
        "\n",
        "print(model)\n",
        "print(f'# of Parameters: {np.sum([np.prod(p.shape) for p in model.parameters()])}')\n",
        "\n",
        "#################################\n",
        "EbNo_range_test = range(4, 7)\n",
        "EbNo_range_train = range(2, 8)\n",
        "std_train = [EbN0_to_std(ii, code.k / code.n) for ii in EbNo_range_train]\n",
        "std_test = [EbN0_to_std(ii, code.k / code.n) for ii in EbNo_range_test]\n",
        "train_dataloader = DataLoader(FEC_Dataset(code, std_train, len=args.batch_size * 1000, zero_cw=True), batch_size=int(args.batch_size),\n",
        "                              shuffle=True, num_workers=args.workers)\n",
        "test_dataloader_list = [DataLoader(FEC_Dataset(code, [std_test[ii]], len=int(args.test_batch_size), zero_cw=False),\n",
        "                                    batch_size=int(args.test_batch_size), shuffle=False, num_workers=args.workers) for ii in range(len(std_test))]\n",
        "#################################\n",
        "\n",
        "print(f\"Training model with code type: {args.code_type}\")\n",
        "print(args.code_type)\n",
        "\n",
        "\n",
        "best_loss = float('inf')\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    loss= train(model, device, train_dataloader, optimizer,\n",
        "                            epoch, LR=scheduler.get_last_lr()[0])\n",
        "    scheduler.step()\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        torch.save(model, os.path.join(args.path, 'best_model'))\n",
        "        print(f'Model Saved')\n",
        "    if epoch % (args.epochs//2) == 0 or epoch in [1,25]:\n",
        "\n",
        "        ### PUSH TO GITHUB ###\n",
        "        !git config --global user.name \"pollyjuice74\"\n",
        "        !git config --global user.email \"hernandez.aht82836@gmail.com\"\n",
        "\n",
        "        !git remote set-url origin https://pollyjuice74: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@github.com/pollyjuice74/DDECC.git\n",
        "\n",
        "        !git add .\n",
        "        !git commit -m \"Add trained model weights\"\n",
        "        !git push origin main\n",
        "        ######################\n",
        "\n",
        "        test(model, device, test_dataloader_list, EbNo_range_test,min_FER=50,max_cum_count=1e6,min_cum_count=1e4)\n",
        "#################################\n",
        "\n",
        "print('Regular Reverse Diffusion')\n",
        "test(model, device, test_dataloader_list, EbNo_range_test,min_FER=100)\n",
        "print('Line Search Reverse Diffusion')\n",
        "model.line_search = True\n",
        "test(model, device, test_dataloader_list, EbNo_range_test,min_FER=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6dvw-yzGoWoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d9288e-4c1e-47d3-f9b1-34e16c8dc1f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 4cc0c5a] Add trained model weights\n",
            " 3 files changed, 0 insertions(+), 0 deletions(-)\n",
            "Enumerating objects: 9, done.\n",
            "Counting objects: 100% (9/9), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (6/6), done.\n",
            "Writing objects: 100% (6/6), 6.10 KiB | 6.10 MiB/s, done.\n",
            "Total 6 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/pollyjuice74/DDECC.git\n",
            "   d008088..4cc0c5a  main -> main\n"
          ]
        }
      ],
      "source": [
        "!git config --global user.name \"pollyjuice74\"\n",
        "!git config --global user.email \"hernandez.aht82836@gmail.com\"\n",
        "\n",
        "!git remote set-url origin https://pollyjuice74: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@github.com/pollyjuice74/DDECC.git\n",
        "\n",
        "!git add .\n",
        "!git commit -m \"Add trained model weights\"\n",
        "!git push origin main"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eijLW5c8cSz7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPIPTLuvN+DrQ3reY6wU0Gy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}